{
    "pretrain": {
        "batch_size": 6,
        "glb_batch_size": 144,
        "glb_batch_token": 589824,
        "lr": 0.01,
        "max_length": 4096,
        "n_gpu": 24,
        "n_node": 3,
        "total_token": 4824289279.999999,
        "train_iters": 163580,
        "warmup_iters": 1635
    }
}